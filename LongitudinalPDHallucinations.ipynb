{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longitudinal cortical thickness and fixel based analysis in Visual Hallucinations\n",
    "\n",
    "- Author: A.Zarkali\n",
    "- Date last updated: 1/1/2021\n",
    "- Aim: Perform all demographics and tract comparisons for longitudinal VIPD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.formula.api import ols\n",
    "import scikit_posthocs as sp\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "# Enable inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database of all demographics\n",
    "df1 = pd.read_excel(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/Visit1Data.xlsx\")\n",
    "df2 = pd.read_excel(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/\\Visit2Data.xlsx\")\n",
    "df = pd.concat((df1, df2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Thickness data\n",
    "thick1 = pd.read_table(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/Session1Aseg.txt\")\n",
    "thick2 = pd.read_table(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\02_StructuralMRI\\02_ThalamicSegmentation\\Session2Aseg.txt\")\n",
    "# thickCortex1 = pd.read_csv(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\02_StructuralMRI\\02_ThalamicSegmentation\\Session1Thickness.csv\")\n",
    "# thickCortex2 = pd.read_csv(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\02_StructuralMRI\\02_ThalamicSegmentation\\Session2Thickness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load thalamic data\n",
    "thalVis1 = pd.read_csv(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/ThalamSegmVH_Visit1.csv\", sep=\",\")\n",
    "thalVis2 = pd.read_csv(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/\\ThalamSegmVH_Visit2.csv\", sep=\",\")\n",
    "thalDif = pd.read_csv(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/\\ThalamusDif.csv\", sep=\",\")\n",
    "# Load tract data\n",
    "fcVis1 = pd.read_table(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/MRI_DATA/Mean_ThalamicTracts/IndividualNuclei/Baseline_fc_Thresholded.txt\")\n",
    "fcDif = pd.read_table(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/MRI_DATA/Mean_ThalamicTracts/IndividualNuclei/VisitDif_fc_Thresholded.txt\")\n",
    "fcVis2 = fcVis1 + fcDif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Extract FS mean TIV\n",
    "participants = [df.Participant.values][0]\n",
    "indeces = []\n",
    "for i in range(len(participants)):\n",
    "    for k in range(len(thick1)):\n",
    "        if participants[i] in thick1[\"Measure:volume\"].iloc[k]:\n",
    "    #thick1[\"Measure:volume\"].iloc[i] in participants:\n",
    "            indeces.append(i)\n",
    "thick1.EstimatedTotalIntraCranialVol[indeces].to_csv(\"ETIV_Session1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the thalamic volumes by ETIV\n",
    "for i in range(len(thalVis2)):\n",
    "    for col in thalVis2.drop(columns=[\"Participant\"]).columns:\n",
    "        thalVis2[col].iloc[i] = thalVis2[col].iloc[i] / df.EstimatedTotalIntraCranialVol.iloc[i]\n",
    "thalVis2.to_csv(\"ThalamicVolumesPercentageTIV_Session2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine clinical and thalamic segmentation data to a single dataframe \n",
    "thalamusVis1 = pd.concat([thalVis1,df], axis=1)\n",
    "thalamusVis2 = pd.concat([thalVis2,df], axis=1)\n",
    "thalamusDif = pd.concat([thalDif,df], axis=1)\n",
    "# Combine clinical and tract data to a single dataframe\n",
    "tractVis1 = pd.concat([fcVis1, df], axis=1)\n",
    "tractVis2 = pd.concat([fcVis2, df], axis=1)\n",
    "tractDif = pd.concat([fcDif, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create a long dataframe format\n",
    "#### Thalamus\n",
    "thalVis1[\"Session\"] = 1\n",
    "thalVis2[\"Session\"] = 2\n",
    "demographics = [\"Age\", \"Gender\", \"PD_VHAny\", \"PD\", \"IntracranialVolume\", \"Time2Scan\"]\n",
    "for col in demographics:\n",
    "    thalVis1[col] = df[col]\n",
    "    thalVis1[\"Time2Scan\"] = 0\n",
    "    thalVis2[col] = df[col]\n",
    "longthal = pd.concat([thalVis1, thalVis2], axis=0)\n",
    "\n",
    "#### Tracts\n",
    "fcVis1[\"Session\"] = 1\n",
    "fcVis2[\"Session\"] = 2\n",
    "demographics = [\"Age\", \"Gender\", \"PD_VHAny\", \"PD\", \"IntracranialVolume\", \"Time2Scan\", \"Participant\"]\n",
    "for col in demographics:\n",
    "    fcVis1[col] = df[col]\n",
    "    fcVis1[\"Time2Scan\"] = 0\n",
    "    fcVis2[col] = df[col]\n",
    "longFC = pd.concat([fcVis1, fcVis2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group thalamic nuclei to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lists to Group thalamic nuclei according to Iglesias et al. A probabilistic atlas of the human thalamic nuclei combining ex vivo MRI and histology. Neuroimage 2018 Dec; 183: 314â€“326\n",
    "LeftAnterior = [\"LeftAV\"]\n",
    "RightAnterior = [\"RightAV\"]\n",
    "LeftLateral = [\"LeftLD\", \"LeftLP\"]\n",
    "RightLateral = [\"RightLD\", \"RightLP\"]\n",
    "LeftVentral = [\"LeftVA\", \"LeftVAmc\", \"LeftVLa\", \"LeftVLp\", \"LeftVPL\", \"LeftVM\"]\n",
    "RightVentral = [\"RightVA\", \"RightVAmc\", \"RightVLa\", \"RightVLp\", \"RightVPL\", \"RightVM\"]\n",
    "LeftIntralaminar = [\"LeftCeM\", \"LeftCL\", \"LeftPc\", \"LeftCM\", \"LeftPf\"]\n",
    "RightIntralaminar = [\"RightCeM\", \"RightCL\", \"RightPc\", \"RightCM\", \"RightPf\"]\n",
    "LeftMedial = [\"LeftPt\", \"LeftMV_Re\", \"LeftMDm\", \"LeftMDl\"]\n",
    "RightMedial = [\"RightPt\", \"RightMV-Re\", \"RightMDm\", \"RightMDl\"]\n",
    "LeftMedialGN = [\"LeftMGN\", \"LeftL_SG\"]\n",
    "RightMedialGN = [\"RightMGN\", \"RightL_SG\"]\n",
    "LeftPulvinar = [\"LeftPuA\", \"LeftPuM\", \"LeftPuL\", \"LeftPuI\"]\n",
    "RightPulvinar = [\"RightPuA\", \"RightPuM\", \"RightPuL\", \"RightPuI\"]\n",
    "LeftPosterior = LeftMedialGN + LeftPulvinar\n",
    "RightPosterior = RightMedialGN + RightPulvinar\n",
    "## List of the columns\n",
    "SumColumns = [\"LeftAnterior\", \"RightAnterior\", \"LeftLateral\", \"RightLateral\", \"LeftVentral\", \"RightVentral\", \"LeftIntralaminar\", \"RightIntralaminar\", \"LeftMedial\", \"RightMedial\", \"LeftPulvinar\", \"RightPulvinar\", \"LeftMedialGN\", \"RightMedialGN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Columns of sum thalamic volumes per nuclei category\n",
    "databases = thalamusVis1, thalamusVis2, thalamusDif\n",
    "for base in databases:\n",
    "    base[\"LeftAnterior\"] = base[\"LeftAV\"]\n",
    "    base[\"RightAnterior\"] = base[\"RightAV\"]\n",
    "    base[\"LeftLateral\"] = base[\"LeftLD\"] + base[\"LeftLP\"]\n",
    "    base[\"RightLateral\"] = base[\"RightLD\"] + base[\"RightLP\"]\n",
    "    base[\"LeftVentral\"] = base[\"LeftVA\"] + base[\"LeftVAmc\"] + base[\"LeftVLa\"] + base[\"LeftVLp\"] + base[\"LeftVPL\"] + base[\"LeftVM\"]\n",
    "    base[\"RightVentral\"] = base[\"RightVA\"] + base[\"RightVAmc\"] + base[\"RightVLa\"] + base[\"RightVLp\"] + base[\"RightVPL\"] + base[\"RightVM\"]\n",
    "    base[\"LeftIntralaminar\"] = base[\"LeftCeM\"] + base[\"LeftCL\"] + base[\"LeftPc\"] + base[\"LeftCM\"] + base[\"LeftPf\"]\n",
    "    base[\"RightIntralaminar\"] = base[\"RightCeM\"] + base[\"RightCL\"] + base[\"RightPc\"] + base[\"RightCM\"] + base[\"RightPf\"]\n",
    "    #base[\"LeftMedial\"] = base[\"LeftMDl\"] + [\"LeftMDm\"] + base[\"LeftPt\"] + base[\"LeftMV_Re\"] \n",
    "    #base[\"RightMedial\"] = base[\"RightPt\"] + base[\"RightMV_Re\"] + [\"RightMDm\"] + base[\"RightMDl\"]\n",
    "    base[\"LeftMedialGN\"] = base[\"LeftMGN\"] + base[\"LeftL_Sg\"]\n",
    "    base[\"RightMedialGN\"] = base[\"RightMGN\"] + base[\"RightL_Sg\"]\n",
    "    base[\"LeftPulvinar\"] = base[\"LeftPuA\"] + base[\"LeftPuM\"] + base[\"LeftPuL\"] + base[\"LeftPuI\"]\n",
    "    base[\"RightPulvinar\"] = base[\"RightPuA\"] + base[\"RightPuM\"] + base[\"RightPuL\"] + base[\"RightPuI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Medial one - loop doesnt work\n",
    "thalamusVis1[\"LeftMedial\"] = thalamusVis1.LeftMDl + thalamusVis1.LeftMDm + thalamusVis1.LeftPt + thalamusVis1.LeftMV_Re\n",
    "thalamusVis1[\"RightMedial\"] = thalamusVis1.RightMDl + thalamusVis1.RightMDm + thalamusVis1.RightPt + thalamusVis1.RightMV_Re\n",
    "thalamusVis2[\"LeftMedial\"] = thalamusVis2.LeftMDl + thalamusVis2.LeftMDm + thalamusVis2.LeftPt + thalamusVis2.LeftMV_Re\n",
    "thalamusVis2[\"RightMedial\"] = thalamusVis2.RightMDl + thalamusVis2.RightMDm + thalamusVis2.RightPt + thalamusVis2.RightMV_Re\n",
    "thalamusDif[\"LeftMedial\"] = thalamusDif.LeftMDl + thalamusDif.LeftMDm + thalamusDif.LeftPt + thalamusDif.LeftMV_Re\n",
    "thalamusDif[\"RightMedial\"] = thalamusDif.RightMDl + thalamusDif.RightMDm + thalamusDif.RightPt + thalamusDif.RightMV_Re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normality check for all columns together\n",
    "\n",
    "### Declare empty variables to hold column names\n",
    "NormallyDistributed = []\n",
    "NonNormallyDistributed = []\n",
    "\n",
    "### Loop through all columns\n",
    "for col in df.columns:\n",
    "    if is_numeric_dtype(df[col]) == True: ## Numeric check\n",
    "        data = df[np.isfinite(df[col])] ## Drop NAs (the shapiro will not calculate statistic if NAs present)\n",
    "        r, p = stats.shapiro(data[col]) ### If less than 0.05 non normally distributed\n",
    "        if p < 0.05: \n",
    "            NonNormallyDistributed.append(col)\n",
    "        else:\n",
    "            NormallyDistributed.append(col)\n",
    "### Save in text files the names of the variables\n",
    "with open('NormallyDistributedVariables.txt', 'w') as filehandle:\n",
    "    for listitem in NormallyDistributed:\n",
    "        filehandle.write('%s\\n' % listitem)\n",
    "with open('NonNormallyDistributedVariables.txt', 'w') as filehandle:\n",
    "    for listitem in NonNormallyDistributed:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Visualise distribution - if want to for individual columns\n",
    "col = \"HADSdepression\"\n",
    "sns.distplot(df[df.PD==1][col])\n",
    "stats.shapiro(df[df.PD==1][col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract group means and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save all group mean and std for each column\n",
    "### Group by PD_VHAny: 0 controls, 1 PD non VH, 2 PD VH\n",
    "dfMean = df.groupby(\"PD_VHAny\").mean()\n",
    "dfMean[\"Type\"] = \"Mean\"\n",
    "dfSTD = df.groupby(\"PD_VHAny\").std()\n",
    "dfSTD[\"Type\"] = \"STD\"\n",
    "pd.concat([dfMean,dfSTD], axis=0).to_csv(\"GroupedDemographics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparisons between 3 groups\n",
    "\n",
    "\n",
    "- Step 1 - Loop through all variables and run ANOVA for normally distributed and Kruskal Wallis for non normally distributed ones\n",
    "- Step 2 - Post hoc testing for those who are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupCompare(variables, group, dataframe, number_groups): \n",
    "    ### Declare empty variables to hold column names\n",
    "    NormallyDistributed = []\n",
    "    NonNormallyDistributed = []\n",
    "    statistic = []\n",
    "    p_value = []\n",
    "    types = []\n",
    "    ### Loop through all columns of a dataframe and check normality\n",
    "    for col in dataframe.columns:\n",
    "        if is_numeric_dtype(dataframe[col]) == True: ## Numeric check\n",
    "            data = dataframe[np.isfinite(dataframe[col])] ## Drop NAs (the shapiro will not calculate statistic if NAs present)\n",
    "            r, p = stats.shapiro(data[col]) ### If less than 0.05 non normally distributed\n",
    "            if p < 0.05: \n",
    "                NonNormallyDistributed.append(col)\n",
    "            else:\n",
    "                NormallyDistributed.append(col)\n",
    "    for var in variables:\n",
    "        if number_groups > 2: \n",
    "            if var in NormallyDistributed: ## Normally distributed then do ANOVA\n",
    "                data=dataframe[np.isfinite(dataframe[var])]\n",
    "                variable = data[var].dropna()\n",
    "                comp = data[group] ### comparison of interest\n",
    "                anova = ols(\"variable ~ C(comp)\", data=data).fit() ### run anova  \n",
    "                r = anova.rsquared_adj ## extract overall model adjusted r statistic\n",
    "                p = anova.f_pvalue ## extract overall model p-value\n",
    "                statistic.append(r)\n",
    "                p_value.append(p)\n",
    "                types.append(\"ANOVA\")\n",
    "            elif var in NonNormallyDistributed: ### Non normally distributed then do Kruskal Wallis\n",
    "                data = dataframe[np.isfinite(dataframe[var])] \n",
    "                ### declare the three series\n",
    "                v1 = data[data[group] == 0][var] \n",
    "                v2 = data[data[group] == 1][var]\n",
    "                v3 = data[data[group] == 2][var]\n",
    "                r,p = stats.kruskal(v1, v2, v3) ### run Kruskal wallis\n",
    "                statistic.append(r)\n",
    "                p_value.append(p)\n",
    "                types.append(\"Kruskal-Wallis\")\n",
    "            else: ### In case any variables were labelled incorrectly\n",
    "                statistic.append(\"NA\")\n",
    "                p_value.append(\"NA\")\n",
    "                types.append(\"NA\")\n",
    "        elif number_groups == 2:\n",
    "            if var in NormallyDistributed: ## Normally distributed then do ttest\n",
    "                data=dataframe[np.isfinite(dataframe[var])]\n",
    "                v1 = data[data.PD_VHAny == 1][var]\n",
    "                v2 = data[data.PD_VHAny == 2][var]\n",
    "                r, p = stats.ttest_ind(v1, v2)\n",
    "                statistic.append(r)\n",
    "                p_value.append(p)\n",
    "                types.append(\"t-test\")\n",
    "            elif var in NonNormallyDistributed: ### Non normally distributed then do Mann-Whitney\n",
    "                data = dataframe[np.isfinite(dataframe[var])] \n",
    "                v1 = data[data.PD_VHAny == 1][var]\n",
    "                v2 = data[data.PD_VHAny == 2][var]\n",
    "                r,p = stats.mannwhitneyu(v1, v2) ### run Kruskal wallis\n",
    "                statistic.append(r)\n",
    "                p_value.append(p)\n",
    "                types.append(\"Mann-Whitney\")\n",
    "            else: ### In case any variables were labelled incorrectly\n",
    "                statistic.append(\"NA\")\n",
    "                p_value.append(\"NA\")\n",
    "                types.append(\"NA\")    \n",
    "    ### Combine results on dataframe\n",
    "    results = pd.DataFrame(data=np.zeros((len(variables), 0))) # empty dataframe\n",
    "    results[\"Variable\"] = variables # variable names\n",
    "    results[\"Statistic\"] = statistic # statistic\n",
    "    results[\"Pvalue\"] = p_value # p_value\n",
    "    results[\"Type\"] = types # type of statistical test used\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\02_StructuralMRI\\02_ThalamicSegmentation\\DemographicsAll3groups.txt\"\n",
    "variables = [line.rstrip('\\n') for line in open(filename)]\n",
    "result = groupCompare(variables,\"PD_VHAny\",df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform comparisons between all 3 groups at once\n",
    "### Load variables for 3 group comparison\n",
    "filename = r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\02_StructuralMRI\\02_ThalamicSegmentation\\DemographicsAll3groups.txt\"\n",
    "variables = [line.rstrip('\\n') for line in open(filename)]\n",
    "\n",
    "## Empty variables to hold results\n",
    "statistic = []\n",
    "p_value = []\n",
    "types = []\n",
    "\n",
    "### Loop through all the variables\n",
    "for var in variables:\n",
    "    if var in NormallyDistributed: ## Normally distributed then do ANOVA\n",
    "        data=df[np.isfinite(df[var])]\n",
    "        variable = data[var].dropna()\n",
    "        group = data.PD_VHAny ### comparison of interest\n",
    "        anova = ols(\"variable ~ C(group)\", data=data).fit() ### run anova  \n",
    "        r = anova.rsquared_adj ## extract overall model adjusted r statistic\n",
    "        p = anova.f_pvalue ## extract overall model p-value\n",
    "        statistic.append(r)\n",
    "        p_value.append(p)\n",
    "        types.append(\"ANOVA\")\n",
    "    elif var in NonNormallyDistributed: ### Non normally distributed then do Kruskal Wallis\n",
    "        data = df[np.isfinite(df[var])] \n",
    "        ### declare the three series\n",
    "        v1 = data[data.PD_VHAny == 0][var] \n",
    "        v2 = data[data.PD_VHAny == 1][var]\n",
    "        v3 = data[data.PD_VHAny == 2][var]\n",
    "        r,p = stats.kruskal(v1, v2, v3) ### run Kruskal wallis\n",
    "        statistic.append(r)\n",
    "        p_value.append(p)\n",
    "        types.append(\"Kruskal-Wallis\")\n",
    "    else: ### In case any variables were labelled incorrectly\n",
    "        statistic.append(\"NA\")\n",
    "        p_value.append(\"NA\")\n",
    "        types.append(\"NA\")\n",
    "### Combine results on dataframe\n",
    "results = pd.DataFrame(data=np.zeros((len(variables), 0))) # empty dataframe\n",
    "results[\"Variable\"] = variables # variable names\n",
    "results[\"Statistic\"] = statistic # statistic\n",
    "results[\"Pvalue\"] = p_value # p_value\n",
    "results[\"Type\"] = types # type of statistical test used\n",
    "results.to_csv(\"GroupComparisons_3Groups.csv\") # export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Post hoc testing\n",
    "# Variables that are significantly different between groups\n",
    "results[results.Pvalue <=0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post hoc tukey test for ANOVA\n",
    "var = \"Stroop_colour_time\"\n",
    "data = df[np.isfinite(df[var])]\n",
    "variable = data[var] # substitute variable sequentially to test all continuous variables following ANOVA\n",
    "group = data.PD_VHAny\n",
    "sp.posthoc_tukey_hsd(variable, group, alpha=0.05)\n",
    "# The contrast appearing as 1 is significant / 0 is non significant / -1 for diagonals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Post hoc dunn test for Kruskal Wallis\n",
    "var = \"Stroop_both_time\"\n",
    "X = [df[df.PD_VHAny == 0][var], df[df.PD_VHAny == 1][var], df[df.PD_VHAny == 2][var]]\n",
    "sp.posthoc_dunn(X) \n",
    "### returns the exact p-values for each comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons between PD groups only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Continuous variables\n",
    "### Load variables for PD group comparison\n",
    "filename = r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\02_StructuralMRI\\02_ThalamicSegmentation\\DemographicsPDgroups.txt\"\n",
    "variables = [line.rstrip('\\n') for line in open(filename)]\n",
    "## Empty variables to hold results\n",
    "statistic = []\n",
    "p_value = []\n",
    "types = []\n",
    "\n",
    "### Loop through all the variables\n",
    "for var in variables:\n",
    "    if var in NormallyDistributed: ## Normally distributed then do ANOVA\n",
    "        data=df[np.isfinite(df[var])]\n",
    "        v1 = data[data.PD_VHAny == 1][var]\n",
    "        v2 = data[data.PD_VHAny == 2][var]\n",
    "        r, p = stats.ttest_ind(v1, v2)\n",
    "        statistic.append(r)\n",
    "        p_value.append(p)\n",
    "        types.append(\"t-test\")\n",
    "    elif var in NonNormallyDistributed: ### Non normally distributed then do Kruskal Wallis\n",
    "        data = df[np.isfinite(df[var])] \n",
    "        v1 = data[data.PD_VHAny == 1][var]\n",
    "        v2 = data[data.PD_VHAny == 2][var]\n",
    "        r,p = stats.mannwhitneyu(v1, v2) ### run Kruskal wallis\n",
    "        statistic.append(r)\n",
    "        p_value.append(p)\n",
    "        types.append(\"Mann-Whitney\")\n",
    "    else: ### In case any variables were labelled incorrectly\n",
    "        statistic.append(\"NA\")\n",
    "        p_value.append(\"NA\")\n",
    "        types.append(\"NA\")\n",
    "### Combine results on dataframe\n",
    "results = pd.DataFrame(data=np.zeros((len(variables), 0))) # empty dataframe\n",
    "results[\"Variable\"] = variables # variable names\n",
    "results[\"Statistic\"] = statistic # statistic\n",
    "results[\"Pvalue\"] = p_value # p_value\n",
    "results[\"Type\"] = types # type of statistical test used\n",
    "results.to_csv(\"GroupComparisons_PDonly.csv\") # export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Categorical variables\n",
    "filename = r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/02_StructuralMRI/02_ThalamicSegmentation/DemographicsPDgroupsCategorical.txt\"\n",
    "variables = [line.rstrip('\\n') for line in open(filename)]\n",
    "\n",
    "## Empty variables to hold results\n",
    "statistic = []\n",
    "p_value = []\n",
    "\n",
    "for var in variables:\n",
    "    data=df[np.isfinite(df[var])]\n",
    "#     data = data[data.PD==1] ## do only in PD\n",
    "    tab = pd.crosstab(data.PD_VHAny,data[var])\n",
    "    r, p, dof, exp = stats.chi2_contingency(tab)\n",
    "    statistic.append(r)\n",
    "    p_value.append(p)\n",
    "### Combine results on dataframe\n",
    "results = pd.DataFrame(data=np.zeros((len(variables), 0))) # empty dataframe\n",
    "results[\"Variable\"] = variables # variable names\n",
    "results[\"ChiSquare\"] = statistic # statistic\n",
    "results[\"Pvalue\"] = p_value # p_value\n",
    "results.to_csv(\"GroupComparisons_PDonlyCategorical.csv\") # export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comparison of longitudinal difference\n",
    "variablesVisit1 = [\"MOCA\", \"MMSE\", \"DigitSpanF\", \"DigitSpanB\", \"Stroop_colour_time\", \"Stroop_both_time\", \"FluencyAnimal\", \"WordRec\", \"LogMem_Delayed\", \"GNT\", \"FluencyLetter\", \"JLO\", \"Hooper\", \"UPDRS\", \"UPDRSMotorScoreonly\", \"LEDD\"]\n",
    "variablesVisit2 = [\"MOCA_Session2\", \"MMSE_Session2\", \"Digit_Span_Forward_Session2\", \"Digit_Span_Backward_Session2\", \"Stroop_colour_time_Session2\", \"Stroop_both_time_Session2\", \"Verbal_fluency_category_Session2\", \"Word_recognition_Session2\", \"Logical_Memory_Delayed_Session2\", \"GNT_Session2\", \"Verbal_fluency_letter_Session2\", \"JLO_Session2\", \"Hooper_Session2\", \"UPDRS_Session2\", \"UPDRSMotorScoreOnly_Session2\", \"LEDD_S2\"]\n",
    "\n",
    "variablesDif = []\n",
    "\n",
    "dfPD = df[df.PD ==1]\n",
    "for x in range(len(variablesVisit1)):\n",
    "    variable = str(variablesVisit1[x] + \"_Dif\")\n",
    "    variablesDif.append(variable)\n",
    "    dfPD[variable] = dfPD[(variablesVisit2[x])] - dfPD[(variablesVisit1[x])] \n",
    "resultsDif = groupCompare(variablesDif, \"PD_VHAny\", dfPD, 2)\n",
    "resultsDif.to_csv(\"GroupDifferences_LongitudinalCognition_PDonly.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare across groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compare individual nuclei or tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loop through all the individual nuclei\n",
    "## Declare the datase\n",
    "data = tractVis1\n",
    "#data = data[data.PD == 1]  ## Select PD only\n",
    "#data = data[data.PD_VHAny!=1] ## Remove PD non VH\n",
    "data[\"groups\"] = 0 \n",
    "vc = {\"IntracranialVolume\": \"IntracranialVolume\", \"Gender\": \"0 + C(Gender)\", \"Age\": \"Age\"} \n",
    "# # Declare empty lists\n",
    "pvalues = []\n",
    "coefficients = []\n",
    "lowerCI = []\n",
    "upperCI = []\n",
    "\n",
    "### Loop through all nuclei \n",
    "#for nucleus in thalVis1.drop(columns=[\"Participant\", \"LeftWhole_thalamus\", \"RightWhole_thalamus\"]).columns: ### for nuclei\n",
    "for nucleus in fcVis1.columns: ### for tracts\n",
    "    # Change the Y variable to each ROI name\n",
    "    formula = nucleus + \" ~ PD\"\n",
    "    md = sm.MixedLM.from_formula(formula, data=data, re_formula=\"1\", vc_formula=vc, groups=data.groups)\n",
    "    mdf = md.fit() # fit the model\n",
    "    ### Select the values I want from the model\n",
    "    p = mdf.pvalues[1]\n",
    "    coef = (mdf.conf_int().iloc[1]).mean()\n",
    "    lower = (mdf.conf_int().iloc[1])[0]\n",
    "    upper = (mdf.conf_int().iloc[1])[1]\n",
    "    ### Append them to the empty lists\n",
    "    pvalues.append(p)\n",
    "    coefficients.append(coef)\n",
    "    lowerCI.append(lower)\n",
    "    upperCI.append(upper)\n",
    "# FDR correct the p-values\n",
    "FDR = sm.stats.multipletests(pvalues, is_sorted=False, alpha=0.05, method=\"fdr_bh\", returnsorted=False)\n",
    "\n",
    "# Merge to Dataframe and export as csv\n",
    "# outdata = pd.DataFrame(data=np.zeros(((len(thalVis1.columns)-3),0))) ### for nuclei\n",
    "# outdata[\"Nucleus\"] = thalVis1.drop(columns=[\"Participant\", \"LeftWhole_thalamus\", \"RightWhole_thalamus\"]).columns ### For nuclei\n",
    "outdata = pd.DataFrame(data=np.zeros((len(fcVis1.columns),0))) ### for tracts\n",
    "outdata[\"Tract\"] = fcVis1.columns ### for tracts\n",
    "outdata[\"Coef\"] = coefficients\n",
    "outdata[\"lowerCI\"] = lowerCI\n",
    "outdata[\"upperCI\"] = upperCI\n",
    "outdata[\"pValues\"] = pvalues\n",
    "outdata[\"FDR\"] = FDR[1]\n",
    "outdata.to_csv(\"FCVis1_PDvsControls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LONGITUDINAL\n",
    "\n",
    "#### Loop through all the individual nuclei\n",
    "## Declare the datase\n",
    "data = thalamusDif\n",
    "data = data[data.PD == 1]\n",
    "# data = data[data.PD_VHAny!=1]\n",
    "data[\"groups\"] = 0 \n",
    "\n",
    "# # Declare empty lists\n",
    "pvalues = []\n",
    "coefficients = []\n",
    "lowerCI = []\n",
    "upperCI = []\n",
    "\n",
    "### Loop through all nuclei \n",
    "for nucleus in thalVis1.drop(columns=[\"Participant\", \"LeftWhole_thalamus\", \"RightWhole_thalamus\"]).columns: ### for nuclei\n",
    "#for nucleus in fcVis1.columns: ### for tracts\n",
    "    vis1volume = str(nucleus + \"Vis_1\")\n",
    "    data[vis1volume] = thalVis1[nucleus]\n",
    "    # Change the Y variable to each ROI name\n",
    "    vc = {\"IntracranialVolume\": \"IntracranialVolume\", \"Gender\": \"0 + C(Gender)\", \"Age\": \"Age\", \"Visit1\":vis1volume} \n",
    "    formula = nucleus + \" ~ C(PD_VHAny)* Time2Scan\"\n",
    "#     formula = nucleus + \" ~ C(PD_VHAny) * Time + \" + vis1volume\n",
    "    md = sm.MixedLM.from_formula(formula, data=data, re_formula=\"1\", vc_formula=vc, groups=data.groups)\n",
    "    mdf = md.fit() # fit the model\n",
    "    ### Select the values I want from the model\n",
    "    p = mdf.pvalues[3]\n",
    "    coef = (mdf.conf_int().iloc[3]).mean()\n",
    "    lower = (mdf.conf_int().iloc[3])[0]\n",
    "    upper = (mdf.conf_int().iloc[3])[1]\n",
    "    ### Append them to the empty lists\n",
    "    pvalues.append(p)\n",
    "    coefficients.append(coef)\n",
    "    lowerCI.append(lower)\n",
    "    upperCI.append(upper)\n",
    "# FDR correct the p-values\n",
    "FDR = sm.stats.multipletests(pvalues, is_sorted=False, alpha=0.05, method=\"fdr_bh\", returnsorted=False)\n",
    "\n",
    "# Merge to Dataframe and export as csv\n",
    "outdata = pd.DataFrame(data=np.zeros(((len(thalVis1.columns)-3),0))) ### for nuclei\n",
    "outdata[\"Nucleus\"] = thalVis1.drop(columns=[\"Participant\", \"LeftWhole_thalamus\", \"RightWhole_thalamus\"]).columns ### For nuclei\n",
    "#outdata = pd.DataFrame(data=np.zeros((len(fcVis1.columns),0))) ### for tracts\n",
    "#outdata[\"Tract\"] = fcVis1.columns ### for tracts\n",
    "outdata[\"Coef\"] = coefficients\n",
    "outdata[\"lowerCI\"] = lowerCI\n",
    "outdata[\"upperCI\"] = upperCI\n",
    "outdata[\"pValues\"] = pvalues\n",
    "outdata[\"FDR\"] = FDR[1]\n",
    "outdata.to_csv(\"Thalamus_LongitudinalPD_VHAny.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Individual ones that fail\n",
    "data = tractVis1\n",
    "# data = data[data.PD == 1]\n",
    "data = data[data.PD_VHAny != 1]\n",
    "data[\"groups\"] = 0 \n",
    "vc = {\"IntracranialVolume\": \"IntracranialVolume\", \"Age\": \"Age\"} \n",
    "formula = \"RightPuM\" + \" ~ PD_VHAny\"\n",
    "md = sm.MixedLM.from_formula(formula, data=data, re_formula=\"1\", vc_formula=vc, groups=data.groups)\n",
    "mdf = md.fit()\n",
    "mdf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LONGITUDINAL LME4\n",
    "import os\n",
    "os.environ[\"R_HOME\"] = r\"C:/PROGRA~1/R/R-3.6.1\"\n",
    "os.environ[\"PATH\"]   = r\"C:/PROGRA~1/R/R-3.6.1\\bin\\x64\" + \";\" + os.environ[\"PATH\"]\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "\n",
    "# Clear longitudinal data\n",
    "data = longthal\n",
    "#data = data[data.PD == 1] ## PD only\n",
    "#data = data[data.PD_VHAny !=1] ## Drop PD non VH\n",
    "data[\"subject\"] = data.Participant.str.slice(start=-3).astype(int) ### Add a subject column as ints\n",
    "dropColumns = demographics + [\"Participant\", \"LeftWhole_thalamus\", \"RightWhole_thalamus\", \"Session\"] ## drop columns to get only the thalami \n",
    "#dropColumns = demographics + [\"Session\"] ## for Tracts\n",
    "\n",
    "# # Declare empty lists\n",
    "pvalues = []\n",
    "T_stats = []\n",
    "coefficients = []\n",
    "lowerCI = []\n",
    "upperCI = []\n",
    "\n",
    "# nuclei = thalVis1.drop(columns=\"Participant\").columns\n",
    "### Loop through all nuclei \n",
    "for nucleus in thalVis1.drop(columns=dropColumns).columns: ### for nuclei\n",
    "    formula = str(nucleus + \" ~ PD * Time2Scan + Age + Gender + IntracranialVolume  + (1 | subject)\")\n",
    "    model = Lmer(formula, data=data)\n",
    "    m = model.fit()\n",
    "    # get the values for the Slope\n",
    "    mdf = m.loc[\"PD:Time2Scan\"]\n",
    "    coef = mdf[\"Estimate\"]\n",
    "    lower = mdf[\"2.5_ci\"]\n",
    "    upper = mdf[\"97.5_ci\"]\n",
    "    p = mdf[\"P-val\"]\n",
    "    t = mdf[\"T-stat\"]\n",
    "    ### Append them to the empty lists\n",
    "    pvalues.append(p)\n",
    "    coefficients.append(coef)\n",
    "    lowerCI.append(lower)\n",
    "    upperCI.append(upper)\n",
    "    T_stats.append(t)\n",
    "    \n",
    "# FDR correct the p-values\n",
    "FDR = sm.stats.multipletests(pvalues, is_sorted=False, alpha=0.05, method=\"fdr_bh\", returnsorted=False)\n",
    "\n",
    "# Merge to Dataframe and export as csv\n",
    "outdata = pd.DataFrame(data=np.zeros((len(thalVis1.drop(columns=dropColumns).columns),0))) ### for nuclei\n",
    "outdata[\"Nucleus\"] = thalVis1.drop(columns=dropColumns).columns ### For nuclei\n",
    "# outdata[\"Tract\"] = fcVis1.drop(columns=dropColumns).columns ### for tracts\n",
    "outdata[\"T-stat\"] = T_stats\n",
    "outdata[\"Coef\"] = coefficients\n",
    "outdata[\"lowerCI\"] = lowerCI\n",
    "outdata[\"upperCI\"] = upperCI\n",
    "outdata[\"pValues\"] = pvalues\n",
    "outdata[\"FDR\"] = FDR[1]\n",
    "outdata.to_csv(\"Thalami_LongitudinalPD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"PD_VisPerf\").Hallucinations_Session2.mean(), df.groupby(\"PD_VisPerf\").Hallucinations_Session2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = df[df1.PD_VisPerf == 1].Hallucinations_Session2\n",
    "v2 = df[df1.PD_VisPerf == 2].Hallucinations_Session2\n",
    "data = df[df.PD_VisPerf != 0]\n",
    "tab = pd.crosstab(data.PD_VisPerf, data.PD_VHAny)\n",
    "stats.chi2_contingency(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare categories of nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop through all the nuclei categories\n",
    "## Declare the datase\n",
    "data = tractDif\n",
    "data = data[data.PD == 1]\n",
    "data[\"groups\"] = 0 \n",
    "#vc = {\"IntracranialVolume\": \"IntracranialVolume\", \"Age\": \"Age\"}\n",
    "vc = {\"IntracranialVolume\": \"IntracranialVolume\", \"Gender\": \"0 + C(Gender)\", \"Age\": \"Age\"} \n",
    "# # Declare empty lists\n",
    "pvalues = []\n",
    "coefficients = []\n",
    "lowerCI = []\n",
    "upperCI = []\n",
    "\n",
    "### Loop through all nuclei \n",
    "for nucleus in fcVis1.columns:\n",
    "    # Change the Y variable to each ROI name\n",
    "    formula = nucleus + \" ~ VH_Any\"\n",
    "    md = sm.MixedLM.from_formula(formula, data=data, re_formula=\"1\", vc_formula=vc, groups=data.groups)\n",
    "    mdf = md.fit()\n",
    "    p = mdf.pvalues[1]\n",
    "#     coef = (mdf.conf_int().loc[\"PD\"]).mean()\n",
    "#     lower = (mdf.conf_int().loc[\"PD\"])[0]\n",
    "#     upper = (mdf.conf_int().loc[\"PD\"])[1]\n",
    "    coef = (mdf.conf_int().iloc[1]).mean()\n",
    "    lower = (mdf.conf_int().iloc[1])[0]\n",
    "    upper = (mdf.conf_int().iloc[1])[1]\n",
    "    pvalues.append(p)\n",
    "    coefficients.append(coef)\n",
    "    lowerCI.append(lower)\n",
    "    upperCI.append(upper)\n",
    "# FDR correct\n",
    "FDR = sm.stats.multipletests(pvalues, is_sorted=False, alpha=0.05, method=\"fdr_bh\", returnsorted=False)\n",
    "\n",
    "# Merge to Dataframe and export as csv\n",
    "outdata = pd.DataFrame(data=np.zeros((len(fcVis1.columns),0))) \n",
    "outdata[\"Nucleus\"] = fcVis1.columns\n",
    "outdata[\"Coef\"] = coefficients\n",
    "outdata[\"lowerCI\"] = lowerCI\n",
    "outdata[\"upperCI\"] = upperCI\n",
    "outdata[\"pValues\"] = pvalues\n",
    "outdata[\"FDR\"] = FDR[1]\n",
    "outdata.to_csv(\"VisitDifThalamus_VHvsNonVH_Categories.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compare Whole thalamus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Repeat with whole thalamus\n",
    "data = thalamusDif\n",
    "data = data[data.PD_VHAny != 1]\n",
    "data[\"groups\"] = 0\n",
    "data[\"Whole_thalamus\"] = data.LeftWhole_thalamus + data.RightWhole_thalamus\n",
    "md = sm.MixedLM.from_formula(\"Whole_thalamus ~ VH_Any\", data=data, re_formula=\"1\", vc_formula=vc, groups=data.groups)\n",
    "mdf = md.fit()\n",
    "mdf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Nuclei Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Barplots and swarmplot with all thalamic volumes between Controls, PD-VH, PD-nonVH\n",
    "### The database you want to loop through (aka Baseline Visit, Visit 2 etc)\n",
    "data = thalamusVis1\n",
    "\n",
    "### Set the style parameters for the graph\n",
    "colors= [\"grey\", \"salmon\", \"brown\"] # colour dictionary\n",
    "sns.set_palette(sns.color_palette(colors)) \n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"poster\", rc={\"font.size\":18,\"axes.titlesize\":18,\"axes.labelsize\":18})   \n",
    "\n",
    "#### Loop through all the nuclei\n",
    "#for nucleus in thalVis1.drop(columns=[\"Participant\", \"LeftWhole_thalamus\", \"RightWhole_thalamus\"]).columns: ## If looping through individual nuclei\n",
    "for nucleus in SumColumns: ### If looping through categories\n",
    "    fig, ax = plt.subplots(figsize=(10,10)) # set size\n",
    "    sns.boxplot(x=\"PD_VHAny\", y=nucleus, data=data) # boxplot\n",
    "    sns.swarmplot(x=\"PD_VHAny\", y=nucleus, data=data, color=\"black\", size=6) # superimposed swarmplot\n",
    "    # filename to save output - this needs to be unique\n",
    "    outname = str(nucleus + \"_Visit1_Barplot.png\") \n",
    "    # Make labels pretty\n",
    "    ax.set_xticklabels([\"Controls\", \"PD non VH\", \"PD VH\"], fontsize=20)\n",
    "    plt.xlabel(\" \")\n",
    "    plt.ylabel(nucleus, fontsize=20)\n",
    "    # Save file, set dpi to 300\n",
    "    plt.savefig(outname, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create longitudinal plots for each nucleus\n",
    "# Set style for the graphs\n",
    "colors= [\"salmon\", \"brown\"]\n",
    "palette=sns.color_palette(colors)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "nuc = [\"RightMDm\", \"LeftPc\"]\n",
    "## Loop through all nuclei\n",
    "for nucleus in nuc:\n",
    "#for nucleus in thalVis1.drop(columns=[\"Participant\", \"LeftWhole_thalamus\", \"RightWhole_thalamus\"]).columns: ## If looping through individual nuclei\n",
    "#for nucleus in SumColumns: ### If looping through categories\n",
    "    # Clear the data \n",
    "    #### Need to select the specific nucleus I want from visit 1 and visit 2 and then melt the database\n",
    "    data = thalVis1[[\"Participant\",nucleus]]\n",
    "    data[str(nucleus + \"_S2\")] = thalVis2[nucleus]\n",
    "    data[\"PD_VHAny\"] = df.PD_VHAny ### This is the group of interest\n",
    "    data = data[data.PD_VHAny !=0]\n",
    "    dataMelt = data.melt(id_vars=\"PD_VHAny\", value_vars=[nucleus, (str(nucleus + \"_S2\"))])\n",
    "    #### Initiate graph pointplot, errorbars:95CI\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    fig = sns.pointplot(y=\"value\", x=\"variable\",hue=\"PD_VHAny\", data=dataMelt, palette=palette, dodge=True, scale=0.5, errwidth=2, legend=True) \n",
    "    #### Make the labels pretty \n",
    "    ax.set_xticklabels([\"Baseline\", \"Session 2\"], fontsize=20)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xlabel(\" \")\n",
    "    plt.ylabel(nucleus, fontsize=20)\n",
    "    ### Add legend with the correct colours\n",
    "    l = plt.legend(title=\"\", loc=\"upper right\", labels= [\"PD non VH\", \"PD VH\"], fontsize=16)\n",
    "    l.legendHandles[0].set_color(colors[0])\n",
    "    l.legendHandles[1].set_color(colors[1])\n",
    "    #l.legendHandles[2].set_color(colors[2])\n",
    "    ### Filename to save output\n",
    "    outname = str(nucleus + \"_Longitudinal.png\")\n",
    "    ### Save\n",
    "    plt.savefig(outname, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create longitudinal plots for each thalamic tract\n",
    "# Set style for the graphs\n",
    "colors= [\"grey\", \"salmon\", \"brown\"]\n",
    "palette=sns.color_palette(colors)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "## Loop through all nuclei\n",
    "for nucleus in fcVis1.columns: ## If looping through individual nuclei\n",
    "#for nucleus in SumColumns: ### If looping through categories\n",
    "    # Clear the data \n",
    "    #### Need to select the specific nucleus I want from visit 1 and visit 2 and then melt the database\n",
    "    data = fcVis1[[nucleus]]\n",
    "    data[str(nucleus + \"_S2\")] = fcVis2[nucleus]\n",
    "    data[\"PD_VHAny\"] = df.PD_VHAny ### This is the group of interest\n",
    "    dataMelt = data.melt(id_vars=\"PD_VHAny\", value_vars=[nucleus, (str(nucleus + \"_S2\"))])\n",
    "    #### Initiate graph pointplot, errorbars:95CI\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    fig = sns.pointplot(y=\"value\", x=\"variable\",hue=\"PD_VHAny\", data=dataMelt, palette=palette, dodge=True, scale=0.5, errwidth=2, legend=True) \n",
    "    #### Make the labels pretty \n",
    "    ax.set_xticklabels([\"Baseline\", \"Session 2\"], fontsize=20)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xlabel(\" \")\n",
    "    plt.ylabel(nucleus, fontsize=20)\n",
    "    ### Add legend with the correct colours\n",
    "    l = plt.legend(title=\"\", loc=\"upper right\", labels= [\"Controls\", \"PD non VH\", \"PD VH\"], fontsize=16)\n",
    "    l.legendHandles[0].set_color(colors[0])\n",
    "    l.legendHandles[1].set_color(colors[1])\n",
    "    l.legendHandles[2].set_color(colors[2])\n",
    "    ### Filename to save output\n",
    "    outname = str(nucleus + \"_Longitudinal.png\")\n",
    "    ### Save\n",
    "    plt.savefig(outname, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Miami and Nuclei correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Thalamic tracts\n",
    "### Set Style\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"poster\", rc={\"font.size\":28,\"axes.titlesize\":18,\"axes.labelsize\":18})   \n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "colors = [\"salmon\", \"firebrick\"]\n",
    "palette = sns.color_palette(colors)\n",
    "\n",
    "cols = [\"MiamiAny\", \"PD_VHAny\", \"Participant\"]\n",
    "exclude = [\"RightVM\", \"LeftVM\", \"RightPt\", \"LeftPt\", \"RightPc\", \"LeftPc\"]\n",
    "for col in fcVis1.columns:\n",
    "    if col not in exclude:\n",
    "        cols.append(col)\n",
    "\n",
    "        data = tractDif[tractDif.PD == 1]\n",
    "data = pd.melt(data[cols], id_vars=[\"PD_VHAny\", \"Participant\", \"MiamiAny\"])\n",
    "\n",
    "sns.scatterplot (y=\"value\", x=\"MiamiAny\", data=data, hue=\"PD_VHAny\", ax=ax, legend=False, palette=palette)\n",
    "sns.regplot (y=\"value\", x=\"MiamiAny\", data=data, scatter=False, ax=ax, color=\"black\", line_kws={\"lw\":2})\n",
    "\n",
    "# Make labels pretty\n",
    "plt.xlabel(\"UM-PDHQ score\")\n",
    "plt.ylabel(\"Thalamic tracts Mean FC change\", fontsize=20)\n",
    "stats.spearmanr(data.value, data.MiamiAny)\n",
    "\n",
    "plt.savefig(\"FCtracts_Miami.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Significant Nuclei\n",
    "\n",
    "#### Thalamic tracts\n",
    "### Set Style\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"poster\", rc={\"font.size\":28,\"axes.titlesize\":18,\"axes.labelsize\":18})   \n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "colors = [\"salmon\", \"firebrick\"]\n",
    "palette = sns.color_palette(colors)\n",
    "\n",
    "cols = [\"MiamiAny\", \"PD_VHAny\", \"RightMDm\", \"LeftPc\"]\n",
    "\n",
    "data = thalamusDif[thalamusDif.PD == 1]\n",
    "data = pd.melt(data[cols], id_vars=[\"PD_VHAny\", \"MiamiAny\"])\n",
    "data = data[data.variable == \"LeftPc\"]\n",
    "\n",
    "sns.scatterplot (y=\"value\", x=\"MiamiAny\", data=data, hue=\"PD_VHAny\", ax=ax, legend=False, palette=palette)\n",
    "sns.regplot (y=\"value\", x=\"MiamiAny\", data=data, scatter=False, ax=ax, color=\"black\", line_kws={\"lw\":2})\n",
    "\n",
    "# Make labels pretty\n",
    "plt.xlabel(\"UM-PDHQ score\")\n",
    "plt.ylabel(\"LeftPc\", fontsize=20)\n",
    "stats.spearmanr(data.value, data.MiamiAny)\n",
    "\n",
    "#plt.savefig(\"LeftPc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualise as percentage change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Clean Data\n",
    "data = fcVis2.copy()\n",
    "data[\"PD_VHAny\"] = df.PD_VHAny\n",
    "## Separate Low and High vis datasets\n",
    "dataHigh = data[data.PD_VHAny == 1]\n",
    "dataLow = data[data.PD_VHAny == 2]\n",
    "## One column for each nucleus\n",
    "nuclei = []\n",
    "for col in fcVis1.columns:\n",
    "    nuclei.append(col)\n",
    "## Declare empty lists to hold results\n",
    "resHigh_mean = np.zeros(len(nuclei))\n",
    "resHigh_lower = np.zeros(len(nuclei))\n",
    "resHigh_upper = np.zeros(len(nuclei))\n",
    "resLow_mean =  np.zeros(len(nuclei))\n",
    "resLow_lower =  np.zeros(len(nuclei))\n",
    "resLow_upper =  np.zeros(len(nuclei))\n",
    "for i in range(len(nuclei)):\n",
    "    ## High Vis\n",
    "    meanHigh = dataHigh[nuclei[i]].mean()\n",
    "    stdHigh = dataHigh[nuclei[i]].std()\n",
    "    resHigh_mean[i] = meanHigh\n",
    "    resHigh_lower[i] = meanHigh - (2*stdHigh)\n",
    "    resHigh_upper[i] = meanHigh + (2*stdHigh)\n",
    "    ## Low Vis\n",
    "    meanLow = dataLow[nuclei[i]].mean()\n",
    "    stdLow = dataLow[nuclei[i]].std()\n",
    "    resLow_mean[i] = meanLow\n",
    "    resLow_lower[i] = meanLow - (2*stdLow)\n",
    "    resLow_upper[i] = meanLow + (2*stdLow)\n",
    "\n",
    "resultsMean = pd.DataFrame(data = nuclei)\n",
    "resultsUpper = pd.DataFrame(data = nuclei)\n",
    "resultsLower = pd.DataFrame(data = nuclei)\n",
    "\n",
    "resultsMean[\"LowVis\"] = resLow_mean\n",
    "resultsUpper[\"LowVis\"] = resLow_upper\n",
    "resultsLower[\"LowVis\"] = resLow_lower\n",
    "resultsMean[\"HighVis\"] = resHigh_mean\n",
    "resultsUpper[\"HighVis\"] = resHigh_upper\n",
    "resultsLower[\"HighVis\"] = resHigh_lower\n",
    "\n",
    "resultsMean.to_csv(\"MeanFC.csv\")\n",
    "resultsUpper.to_csv(\"UpperFC.csv\")\n",
    "resultsLower.to_csv(\"LowerFC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"poster\", rc={\"font.size\":12,\"axes.titlesize\":12,\"axes.labelsize\":12})   \n",
    "results = pd.read_csv(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\02_StructuralMRI\\02_ThalamicSegmentation\\Visit2_FC_Perc.csv\")\n",
    "\n",
    "### Select the Left or Right only\n",
    "results = results[results[\"0\"].str.contains(\"Right\")]\n",
    "\n",
    "colorsSig = [\"lightgray\", \"brown\", \"royalblue\"]\n",
    "\n",
    "palette = sns.color_palette(colorsSig)\n",
    "fig = sns.catplot(x=\"VH\", y=\"0\", data=results, hue=\"Significant\", kind=\"box\", orient=\"h\", legend=False, fliersize=0, whis=0, linewidth=1, height=20, aspect=0.6, sharey=True, palette=palette)\n",
    "fig.set_axis_labels(\"\", \"\")\n",
    "\n",
    "plt.xlim(-1,2)\n",
    "#plt.xlim(-0.25,0)\n",
    "fig.savefig(\"Visit2_TractFC_Right\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra for Hippocampal Volume - FBA correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"HipL\"] = thick1[\"Left-Hippocampus\"]\n",
    "df[\"HipR\"] = thick1[\"Right-Hippocampus\"]\n",
    "df[\"WMVol\"] = thick1[\"CerebralWhiteMatterVol\"]\n",
    "df[\"eTIV\"] = thick1[\"EstimatedTotalIntraCranialVol\"]\n",
    "v1 = df[df.PD_VisPerf == 0].eTIV.dropna()\n",
    "v2 = df[df.PD_VisPerf == 1].eTIV.dropna()\n",
    "v3 = df[df.PD_VisPerf == 2].eTIV.dropna()\n",
    "stats.kruskal(v1,v2,v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Post hoc dunn test for Kruskal Wallis\n",
    "X = [v1,v2,v3]\n",
    "sp.posthoc_dunn(X) \n",
    "### returns the exact p-values for each comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA test:\n",
    "data=df\n",
    "#data[\"DigitSpanF_dif\"] = data.Verbal_fluency_letter_Session2 - data.FluencyLetter\n",
    "data = data[np.isfinite(data.eTIV)]\n",
    "variable = data.eTIV.dropna()\n",
    "group = data.PD_VisPerf\n",
    "\n",
    "anova = ols(\"variable ~ C(group)\", data=data).fit()  \n",
    "anova.summary()\n",
    "\n",
    "# Prob(F-statistic): overall p- value\n",
    "# Intercept: first variable group (for example in this is BGC/Interhemispheric)\n",
    "# R-squared: effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
